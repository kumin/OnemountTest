{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "#### Create a program that produces a typed parquet file\n",
    "result was saved in directory 'data/green_tripdata_2013-09'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- vendorid: string (nullable = true)\n",
      " |-- lpep_pickup_datetime: string (nullable = true)\n",
      " |-- lpep_dropoff_datetime: string (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- ratecodeid: string (nullable = true)\n",
      " |-- pickup_longitude: string (nullable = true)\n",
      " |-- pickup_latitude: string (nullable = true)\n",
      " |-- dropoff_longitude: string (nullable = true)\n",
      " |-- dropoff_latitude: string (nullable = true)\n",
      " |-- passenger_count: string (nullable = true)\n",
      " |-- trip_distance: string (nullable = true)\n",
      " |-- fare_amount: string (nullable = true)\n",
      " |-- extra: string (nullable = true)\n",
      " |-- mta_tax: string (nullable = true)\n",
      " |-- tip_amount: string (nullable = true)\n",
      " |-- tolls_amount: string (nullable = true)\n",
      " |-- ehail_fee: string (nullable = true)\n",
      " |-- total_amount: string (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- trip_type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .master('local') \\\n",
    "    .appName('Onemount Test') \\\n",
    "    .getOrCreate()\n",
    "df = spark.read.csv('data/green_tripdata_2013-09.csv', header = True)\n",
    "\n",
    "for column_name in df.columns:\n",
    "    df = df.withColumnRenamed(column_name, column_name.replace(\" \", \"\").lower())\n",
    "\n",
    "df.printSchema()\n",
    "\n",
    "df.repartition(1).write.mode('overwrite').parquet('data/green_tripdata_2013-09')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "#### Create a derived dataset, from the one created above\n",
    "result was saved in directory 'data/nyc_taxi_analysis'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duration in seconds of the trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+-------------+\n",
      "|lpep_pickup_datetime|lpep_dropoff_datetime|trip_duration|\n",
      "+--------------------+---------------------+-------------+\n",
      "| 2013-09-01 00:02:00|  2013-09-01 00:54:51|         3171|\n",
      "| 2013-09-01 00:02:34|  2013-09-01 00:20:59|         1105|\n",
      "| 2013-09-01 00:03:06|  2013-09-01 00:28:03|         1497|\n",
      "| 2013-09-01 00:03:30|  2013-09-01 00:23:02|         1172|\n",
      "| 2013-09-01 00:05:12|  2013-09-01 00:30:55|         1543|\n",
      "| 2013-09-01 00:05:18|  2013-09-01 00:23:31|         1093|\n",
      "| 2013-09-01 00:05:51|  2013-09-01 00:13:32|          461|\n",
      "| 2013-09-01 00:07:01|  2013-09-01 00:13:56|          415|\n",
      "| 2013-09-01 00:07:55|  2013-09-01 00:24:19|          984|\n",
      "| 2013-09-01 00:07:58|  2013-09-01 00:38:32|         1834|\n",
      "| 2013-09-01 00:08:30|  2013-09-01 00:13:58|          328|\n",
      "| 2013-09-01 00:09:25|  2013-09-01 00:27:14|         1069|\n",
      "| 2013-09-01 00:09:41|  2013-09-01 00:17:37|          476|\n",
      "| 2013-09-01 00:11:14|  2013-09-01 00:16:05|          291|\n",
      "| 2013-09-01 00:11:17|  2013-09-01 00:34:44|         1407|\n",
      "| 2013-09-01 00:11:26|  2013-09-01 00:21:45|          619|\n",
      "| 2013-09-01 00:11:46|  2013-09-01 00:27:51|          965|\n",
      "| 2013-09-01 00:15:01|  2013-09-01 00:26:34|          693|\n",
      "| 2013-09-01 00:15:27|  2013-09-01 00:24:30|          543|\n",
      "| 2013-09-01 00:15:40|  2013-09-01 00:23:37|          477|\n",
      "+--------------------+---------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df = spark.read.parquet('data/green_tripdata_2013-09')\n",
    "\n",
    "timeDiff = F.unix_timestamp('lpep_dropoff_datetime')- F.unix_timestamp('lpep_pickup_datetime')\n",
    "df = df.withColumn('trip_duration', timeDiff)\n",
    "\n",
    "df.createOrReplaceTempView('nyc_taxi')\n",
    "df_sql = spark.sql('''\n",
    "    SELECT lpep_pickup_datetime, lpep_dropoff_datetime, trip_duration FROM nyc_taxi\n",
    "''')\n",
    "\n",
    "df_sql.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An int encoding to indicate if the pickup or dropoff locations were at JFK airport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no time for researching, so i copied it on internet\n",
    "import math\n",
    "def cal_bounding_box(longitude:float, latitude:float):\n",
    "    R = 6371  # earth radius in km\n",
    "    radius = 5 # km\n",
    "    min_lon = longitude - math.degrees(radius/R/math.cos(math.radians(latitude)))\n",
    "    max_lon = longitude + math.degrees(radius/R/math.cos(math.radians(latitude)))\n",
    "    min_lat = latitude - math.degrees(radius/R)\n",
    "    max_lat = latitude + math.degrees(radius/R)\n",
    "    \n",
    "    return min_lon, max_lon, min_lat, max_lat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|no_jfk_airport|\n",
      "+--------------+\n",
      "|           893|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType, FloatType\n",
    "\n",
    "longitude_jfk_airport = -73.7787443\n",
    "latitude_jfk_airport = 40.6398262\n",
    "\n",
    "min_lon, max_lon, min_lat, max_lat = cal_bounding_box(longitude_jfk_airport, latitude_jfk_airport)\n",
    "\n",
    "is_jfk_airport = F.udf(lambda p_lon, p_lat, d_lon, d_lat: \n",
    "                       1 if (min_lon<=p_lon and p_lon <= max_lon and min_lat <= p_lat and p_lat <= max_lat) \n",
    "                           or (min_lon<=d_lon and d_lon <= max_lon and min_lat <= d_lat and d_lat <= max_lat)\n",
    "                       else 0, IntegerType())\n",
    "\n",
    "df = df.withColumn('relative_jfk_airport', \n",
    "                   is_jfk_airport(df.pickup_longitude.cast(FloatType()), \n",
    "                                  df.pickup_latitude.cast(FloatType()), \n",
    "                                  df.dropoff_longitude.cast(FloatType()), \n",
    "                                  df.dropoff_latitude.cast(FloatType())))\n",
    "\n",
    "df.createOrReplaceTempView('nyc_taxi')\n",
    "df_sql = spark.sql('''\n",
    "    SELECT count(*) no_jfk_airport FROM nyc_taxi WHERE relative_jfk_airport = 1\n",
    "''')\n",
    "\n",
    "df_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.repartition(1).write.mode('overwrite').parquet('data/nyc_taxi_analysis')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
